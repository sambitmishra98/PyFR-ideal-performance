{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sambitmishra98/PyFR-ideal-performance/blob/main/performance_projection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8goTmJ_YllWw"
      },
      "source": [
        "# Projected performance computation from mesh\n",
        "\n",
        "In this document, we aim to compare the performance of expected PyFR performance in comparison with actual performance.\n",
        "\n",
        "The expected performance is computed by understanding inputs and outputs to all kernels used for computation.\n",
        "\n",
        "The actual performance is computed using `perf_counter()` and looking at wall-time in the solution file. For example, actual performance of Intel MAX GPUs is shown in a [Google Docs file](https://docs.google.com/document/d/1yX7JqTTsXRikTtzRon-03TgRGceByce075N4-Ptp7cI/edit?usp=sharing) (Restricted access). The latter method was used to benchmark performance of PyFR on A100 GPUs in a paper: [Scaling Study of Flow Simulations on Composable Cyberinfrastructure](https://doi.org/10.1145/3569951.3597565)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Global variables\n",
        "\n",
        "size_of_float = 4 \n",
        "precision_size = {'single': size_of_float, \n",
        "                  'double': 2*size_of_float}\n",
        "\n",
        "etypes = ['tet', 'pyr', 'pri', 'hex',]\n",
        "element_counts = {etype: 0 for etype in etypes}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bqwp4CQomevV"
      },
      "source": [
        "## Performance details from configuration file\n",
        "\n",
        "Following the configurations as given in [PyFR documentation](https://pyfr.readthedocs.io/en/latest/user_guide.html#configuration-file-ini).\n",
        "Only those relevant to performance computation is declared below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "N06qEkWllj5N"
      },
      "outputs": [],
      "source": [
        "# [backend]\n",
        "precision = 'double'\n",
        "\n",
        "# [solver]\n",
        "system = 'navier-stokes'\n",
        "order = 2\n",
        "\n",
        "# [solver-time-integrator]\n",
        "scheme = 'rk4'\n",
        "tstart = 0\n",
        "tend = 1.0001\n",
        "dt = 0.0001"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yja6bNEZqmlc"
      },
      "source": [
        "## Processing data from mesh\n",
        "\n",
        "\n",
        "Details of how mesh size may be obtained is found in plugin path `pyfr/plugins/benchmark.py` in benchmark branch in [sambitmihsra98/PyFR.git](https://github.com/sambitmishra98/PyFR.git).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "id": "p8DVgaBkqmFP"
      },
      "outputs": [],
      "source": [
        "ndims = 3\n",
        "nvars = ndims + 2                   # [ρ, ρu, ρv, (ρw), ρE]\n",
        "\n",
        "element_counts['hex'] = 86**3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "so08BhoBr5Hz"
      },
      "source": [
        "## Degrees of Freedom (DoFs) calculation\n",
        "\n",
        "An analysis of Flux Reconstruction schemes on Tetrahedral elements may be found in [this paper](https://doi.org/10.1007/s10915-016-0204-y). In general, we have ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "id": "MZSOB5PDrwZd"
      },
      "outputs": [],
      "source": [
        "def edof(etype, order):\n",
        "    if etype == 'tri':\n",
        "        Nu = (order+1)*(order+2)/2\n",
        "        Nf = 3*(order+1)\n",
        "    elif etype == 'quad':\n",
        "        Nu =   (order+1)**2\n",
        "        Nf = 4*(order+1)\n",
        "    elif etype == 'tet':\n",
        "        Nu = (order+3)*edof('tri', order)[0]//3\n",
        "        Nf =         4*edof('tri', order)[0]\n",
        "    elif etype == 'pyr':\n",
        "        Nu = (2*order+3)*edof('tri', order)[0]//3\n",
        "        Nf =           4*edof('tri', order)[0] +   edof('quad', order)[0]\n",
        "    elif etype == 'pri':\n",
        "        Nu = (order+1)*edof('tri', order)[0]\n",
        "        Nf =         2*edof('tri', order)[0] + 3*edof('quad', order)[0]\n",
        "    elif etype == 'hex':\n",
        "        Nu = (order+1)*edof('quad', order)[0]\n",
        "        Nf =         6*edof('quad', order)[0]\n",
        "    else:\n",
        "        raise Exception(\"Not implemented yet\")\n",
        "\n",
        "    NNuf = Nu*Nf    # Matrix of size Nu x Nf\n",
        "    NNuu = Nu*Nu    # Matrix of size Nu x Nu\n",
        "\n",
        "    return int(Nu), int(Nf), int(NNuf), int(NNuu)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "id": "UciMJZclxcu-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of degrees of freedom: \n",
            "solution points: \t\t17173512 \n",
            "Flux points: \t\t\t34347024 \n",
            "solution --> flux matrices: \t927369648 \n",
            "scalar--> scalar matrices: \t463684824\n"
          ]
        }
      ],
      "source": [
        "# Get total number of degrees of freedom on the basis of the element counts and the element type\n",
        "dofs_s = sum(n*edof(etype, order)[0] for etype, n in element_counts.items())\n",
        "dofs_f = sum(n*edof(etype, order)[1] for etype, n in element_counts.items())\n",
        "M_sf   = sum(n*edof(etype, order)[2] for etype, n in element_counts.items())\n",
        "M_ss   = sum(n*edof(etype, order)[3] for etype, n in element_counts.items())\n",
        "print(f\"Total number of degrees of freedom: \\nsolution points: \\t\\t{dofs_s} \\nFlux points: \\t\\t\\t{dofs_f} \\nsolution --> flux matrices: \\t{M_sf} \\nscalar--> scalar matrices: \\t{M_ss}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Storage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Size of registers for explicit RK stages is as per `stepper_nregs` found in `pyfr/integrators/std/steppers.py` \n",
        "\n",
        "(plus one for the previous solution maybe?)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {},
      "outputs": [],
      "source": [
        "rk_registers = {'euler': 1, \n",
        "                'rk4'  : 4,}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "scalar u: 2.559 GB\n",
            "vector u: 1.919 GB\n",
            "S matrix u: 1.152 GB\n",
            "1/|J| u: 0.128 GB\n",
            "scalar f: 1.280 GB\n",
            "vector f: 3.839 GB\n",
            "n/|n| i: 0.384 GB\n",
            "|n| i: 0.256 GB\n",
            "scalar view i: 0.256 GB\n",
            "vector view i: 0.384 GB\n",
            "total: 12.156 GB\n"
          ]
        }
      ],
      "source": [
        "# Storage values in bytes\n",
        "solution_storages = {\n",
        "       'scalar u': precision_size[precision]*nvars*dofs_s*rk_registers[scheme],\n",
        "       'vector u': precision_size[precision]*nvars*dofs_s*ndims,\n",
        "     'S matrix u': precision_size[precision]*dofs_s*ndims**2,\n",
        "        '1/|J| u': precision_size[precision]*dofs_s,\n",
        "                    }     \n",
        "\n",
        "# Flux\n",
        "flux_storages = {\n",
        "     'scalar f': precision_size[precision]*nvars*dofs_f,\n",
        "     'vector f': precision_size[precision]*nvars*dofs_f*ndims if system == 'navier-stokes' else 0,\n",
        "}\n",
        "# Interface-normal storages\n",
        "interface_normal_storages = {\n",
        "           'n/|n| i': precision_size[precision]*dofs_f*ndims/2,\n",
        "             '|n| i': precision_size[precision]*dofs_f,\n",
        "     'scalar view i': precision_size[ 'single']*dofs_f*2,\n",
        "     'vector view i': precision_size[ 'single']*dofs_f*ndims if system == 'navier-stokes' else 0,\n",
        "}\n",
        "\n",
        "storages = solution_storages|flux_storages|interface_normal_storages\n",
        "storages['total'] = sum(storages.values())\n",
        "\n",
        "for key, val in storages.items():\n",
        "     print(f\"{key}: {val/1024**3:.3f} GB\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Over one sweep of the integrator ...\n",
        "Total number of computations performed is a function of kernels.\n",
        "The inputs, outputs and computations in each kernel needs to be understood."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ... total number of floating point operations performed "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "M0        :       8.64 GFLOP\n",
            "M132      :      12.96 GFLOP\n",
            "M3        :       8.64 GFLOP\n",
            "M460      :      12.96 GFLOP\n",
            "M6        :      25.91 GFLOP\n",
            "M5        :      25.91 GFLOP\n",
            "Gradcoru  :       1.44 GFLOP\n",
            "Tflux     :       3.02 GFLOP\n",
            "Rsolves   :       4.30 GFLOP\n",
            "Conu      :       0.00 GFLOP\n",
            "Rcpdjac   :       0.08 GFLOP\n",
            "\n",
            "\n",
            "GFLOP, stage: \t103.85\n",
            "Matrices: \t 95.00 \t91.48%,\n",
            "Others  : \t  8.76 \t 8.44%,\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Store dictionary of computations, inputs and outputs\n",
        "\n",
        "soln_flux_matrix_computations = sum([n*edof(k,order)[0]*edof(k,order)[1] for k, n in element_counts.items()])*2*nvars\n",
        "soln_soln_matrix_computations = sum([n*edof(k,order)[0]*edof(k,order)[0] for k, n in element_counts.items()])*2*nvars*ndims\n",
        "\n",
        "if ndims == 2:\n",
        "    if system == 'euler':\n",
        "        non_Ms = {'Gradcoru':         0, 'Tflux':  44*dofs_s, 'Rsolves':  92*dofs_f//2,}\n",
        "    else:\n",
        "        non_Ms = {'Gradcoru': 32*dofs_f, 'Tflux':  91*dofs_s, 'Rsolves': 200*dofs_f//2,}\n",
        "elif ndims == 3:\n",
        "    if system == 'euler':\n",
        "        non_Ms = {'Gradcoru':         0, 'Tflux': 105*dofs_s, 'Rsolves': 140*dofs_f//2,}\n",
        "    else:\n",
        "        non_Ms = {'Gradcoru': 90*dofs_s, 'Tflux': 189*dofs_s, 'Rsolves': 269*dofs_f//2,}\n",
        "#                                                         https://github.com/sambitmishra98/PyFR/blob/benchmark/pyfr/.................................\n",
        "# Computations\n",
        "Ms = {'M0'  : soln_flux_matrix_computations,                                            # disu,            u*f      solvers/baseadvec/elements.py#L73\n",
        "      'M132': soln_soln_matrix_computations,                                            # qptsu,           dims*u*u solvers/baseadvec/elements.py#L90\n",
        "      'M3'  : soln_flux_matrix_computations,                                            # tdivtpcorf,      u*f      solvers/baseadvec/elements.py#L97\n",
        "      'M460': soln_soln_matrix_computations       if system == 'navier-stokes' else 0,  # tgradpcoru_upts, u*u      solvers/baseadvecdiff/elements.py#L34 \n",
        "      'M6'  : soln_flux_matrix_computations*ndims if system == 'navier-stokes' else 0,  # tgradcoru_upts,  dims*u*f solvers/baseadvecdiff/elements.py#L38\n",
        "      'M5'  : soln_flux_matrix_computations*ndims if system == 'navier-stokes' else 0,  # mul,             dims*u*f solvers/baseadvecdiff/elements.py#L68\n",
        "}\n",
        "\n",
        "others={'Conu'    : 0,\n",
        "        'Rcpdjac' : nvars*dofs_s, \n",
        "}\n",
        "\n",
        "kernels = Ms|non_Ms|others\n",
        "\n",
        "# Neatly print all kernel values, with their names and values aligned\n",
        "\n",
        "print(*[f\"{k:<10}: {v/(1024**3):>10.2f} GFLOP\" for k, v in kernels.items()], sep='\\n')\n",
        "\n",
        "\n",
        "print(f\"\\n\\nGFLOP, stage: \\t{sum(kernels.values())/(1024**3):6.2f}\")\n",
        "print(f\"Matrices: \\t{sum(Ms.values())    /(1024**3):>6.2f} \\t{sum(Ms.values())    /sum(kernels.values())*100:>5.2f}%,\\n\"\n",
        "      f\"Others  : \\t{sum(non_Ms.values())/(1024**3):>6.2f} \\t{sum(non_Ms.values())/sum(kernels.values())*100:>5.2f}%,\\n\"\n",
        "      )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ... total reads and writes performed\n",
        "\n",
        "Matrix multiplications are the costliest parts. Hence, vector multiplications shall be ignored and only M-related computations shall be considered.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vector reads (in GB): 0.206082144\n",
            "Matrix reads (in GB): 44.513743104\n",
            "Total writes (in GB): 0.103041072\n"
          ]
        }
      ],
      "source": [
        "vector_reads  = {\n",
        "    'M0'  :       dofs_s,\n",
        "    'M132': ndims*dofs_s,\n",
        "    'M3'  :       dofs_f,\n",
        "    'M460':       dofs_s,\n",
        "    'M6'  : ndims*dofs_f,\n",
        "    'M5'  : ndims*dofs_f,\n",
        "    }\n",
        "\n",
        "cached_matrix_reads = {\n",
        "    'M0'  :       M_sf,\n",
        "    'M132': ndims*M_ss,\n",
        "    'M3'  :       M_sf,\n",
        "    'M460':       M_ss,\n",
        "    'M6'  : ndims*M_sf,\n",
        "    'M5'  : ndims*M_sf,\n",
        "    }\n",
        "\n",
        "vector_writes = {\n",
        "    'M0'  :       dofs_f,\n",
        "    'M132':       dofs_s,\n",
        "    'M3'  :       dofs_s,\n",
        "    'M460':       dofs_s,\n",
        "    'M6'  :       dofs_s,\n",
        "    'M5'  :       dofs_s,\n",
        "    }\n",
        "\n",
        "communication_per_timestep = max(sum(vector_reads.values()) + sum(cached_matrix_reads.values()), sum(vector_writes.values()))\n",
        "\n",
        "print(f\"Vector reads (in GB): {sum(vector_reads.values())/1e9}\")\n",
        "print(f\"Matrix reads (in GB): {sum(cached_matrix_reads.values())/1e9}\")\n",
        "print(f\"Total writes (in GB): {sum(vector_writes.values())/1e9}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Performance comparison\n",
        "\n",
        "We get the reported performance of accelerators from specifications sheets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {},
      "outputs": [],
      "source": [
        "memory_size = { # in GB\n",
        "    'Intel(R) Data Center GPU Max 1100': 48,\n",
        "}\n",
        "memory_bandwidth = { # in GB/s\n",
        "    'Intel(R) Data Center GPU Max 1100': 1228.8,\n",
        "}\n",
        "\n",
        "theoretical_single_precision_performance = { # In teraflops\n",
        " 'Intel(R) Data Center GPU Max 1100': 22.22,                  # https://www.techpowerup.com/gpu-specs/data-center-gpu-max-1100.c4066\n",
        "}\n",
        "\n",
        "theoretical_double_precision_performance = { # Teraflops\n",
        " 'Intel(R) Data Center GPU Max 1100': 22.22,                  # https://www.techpowerup.com/gpu-specs/data-center-gpu-max-1100.c4066\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Practical performance\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Number of computations for explicit RK stages is as per `stepper_order` found in `pyfr/integrators/std/steppers.py`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {},
      "outputs": [],
      "source": [
        "rk_stage_computations = {'euler': 1, \n",
        "                         'rk4'  : 4,}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tested performance of simulations (TGV)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {},
      "outputs": [],
      "source": [
        "practical_single_precision_performance = { # GDoF/s\n",
        " 'Intel(R) Data Center GPU Max 1100': 2.25,                 # https://docs.google.com/document/d/1yX7JqTTsXRikTtzRon-03TgRGceByce075N4-Ptp7cI/edit?usp=sharing\n",
        "}\n",
        "\n",
        "practical_double_precision_performance = { # Teraflops\n",
        " 'Intel(R) Data Center GPU Max 1100': 1.25,                 # https://docs.google.com/document/d/1yX7JqTTsXRikTtzRon-03TgRGceByce075N4-Ptp7cI/edit?usp=sharing\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Double precision performance: 1.25 GDoF/s\n",
            "Total number of computations performed per second (FLOPS): 5.0 GFLOPS\n"
          ]
        }
      ],
      "source": [
        "for dp in practical_double_precision_performance.values():\n",
        "    print(f\"Double precision performance: {dp} GDoF/s\")\n",
        "    print(f\"Total number of computations performed per second (FLOPS): {dp*rk_stage_computations[scheme]} GFLOPS\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0612244897959184"
            ]
          },
          "execution_count": 146,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "52/49\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNhFGpyR+VOyaG8cElAGZdJ",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
